predicted
pp <- grams[grep(paste("^", predicted, "$", sep=""), grams$word), ]
predicted$count <- grams[grep(paste("^", predicted, "$", sep=""), grams$word), ]
predicted[ , (nlength+1)] <- grams[grep(paste("^", predicted[,nlength], "$", sep=""), grams$word), ]
predicted <- t(data.frame(strsplit(n$word, " ")))
row.names(predicted) <- NULL
predicted[ , (nlength+1)] <- grams[grep(paste("^", predicted[,nlength], "$", sep=""), grams$word), ]
grep(paste("^", predicted[,nlength], "$", sep=""), grams$word)
predicted[,nlength]
for (g in 1:length(predicted[,1])) predicted$freq[g] <- grams[grep(paste("^", predicted[g,nlength], "$", sep=""), grams$word), ]
predicted <- t(data.frame(strsplit(n$word, " ")))
row.names(predicted) <- NULL
#predicted <- predicted[ , nlength]
for (g in 1:length(predicted[,1])) predicted$freq[g] <- grams[grep(paste("^", predicted[g,nlength], "$", sep=""), grams$word), ]
predicted
for (g in 1:length(predicted[,1])) predicted[g, nlength+1] <- grams[grep(paste("^", predicted[g,nlength], "$", sep=""), grams$word), ]
predicted$freq <- 0
predicted <- t(as.data.frame(strsplit(n$word, " ")))
View(predicted)
predicted$freq <- 0
predicted
n$word
predicted <- as.data.frame(strsplit(n$word, " "))
predicted
predicted <- as.data.frame(strsplit(n$word, " "))[,nlength]
predicted
predicted <- t(as.data.frame(strsplit(n$word, " ")))[,nlength]
predicted
row.names(predicted) <- NULL
predicted
predicted <- t(as.data.frame(strsplit(n$word, " ")))[,nlength]
row.names(predicted) <- NULL
pp <- cbind(predicted, rep(0, length(predicted)))
pp
row.names(pp) <- NULL
for (g in 1:length(predicted[,1])) predicted[g, nlength+1] <- grams[grep(paste("^", predicted[g,nlength], "$", sep=""), grams$word), ]
for (g in 1:length(pp[,1])) pp[g, nlength+1] <- grams[grep(paste("^", pp[g,nlength], "$", sep=""), grams$word), ]
1:length(pp[,1])
pp[g, nlength+1]
nlength
View(pp)
for (g in 1:length(pp[,1])) pp[g, nlength] <- grams[grep(paste("^", pp[g,nlength], "$", sep=""), grams$word), ]
pp[g, nlength]
g
for (g in 1:length(pp[,1])) pp[g, nlength] <- grams[grep(paste("^", pp[g,nlength-1], "$", sep=""), grams$word), ]
grep(paste("^", pp[g,nlength-1], "$", sep="")
, grams$word
)
paste("^", pp[g,nlength-1], "$", sep="")
grep(paste("^", pp[g,nlength-1], "$", sep=""), grams$word)
grep("francisco", grams$word)
for (g in 1:length(pp[,1])) pp[g, nlength] <- onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), ]
onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), ]
for (g in 1:length(pp[,1])) pp[g, nlength] <- onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
g
onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
paste("^", pp[g,nlength-1], "$", sep="")
for (g in 1:length(pp[,1])) {
x <- onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
if (x!=0) {
pp[g, nlength] <- x
} else {  }
}
for (g in 1:length(pp[,1])) {
x <- onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
if (length(x)!=0) {
pp[g, nlength] <- x
} else {  }
}
pp
n$lastprob <- pp[,nlength]
n
n$lastCount <- pp[,nlength]
n
str(b)
str(n)
n$lastCount <- as.numeric(pp[,nlength])
str(n)
n$pKN <- max(n$freq - delta) / m$freq[1] + (delta/m$freq[1]) * n$freq * ( n$lastCount / dim(bigrams)[1])
n
n$prob <- n$freq/m$freq[1]
n
max(n$freq[2] - delta, 0)
m$freq[1]
n$freq[2]
165.2039/627
.79/672
.79/627
176/42072
.2634 + .00125 * 166 * .004183305
n$pKN <- max(n$freq - delta, 0) / m$freq[1] + (delta/m$freq[1]) * n$freq * ( n$lastCount / dim(bigrams)[1])
n
max(n$freq - delta, 0) / m$freq[1]
n$pKN <- (max(n$freq - delta, 0) / m$freq[1]) + (delta/m$freq[1]) * n$freq * ( n$lastCount / dim(bigrams)[1])
n
m$freq[1]
n <- n[2,]
n
max(n$freq - delta, 0)
m$freq[1]
delta/m$freq[1]
n$freq
n$lastCount
dim(bigrams)[1]
n$pKN <- (max(n$freq - delta, 0) / m$freq[1]) + (delta/m$freq[1]) * n$freq * ( n$lastCount / dim(bigrams)[1])
n
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
# get predicted word counts
predicted <- t(as.data.frame(strsplit(n$word, " ")))[,nlength]
pp <- cbind(predicted, rep(0, length(predicted)))
row.names(pp) <- NULL
for (g in 1:length(pp[,1])) {
x <- onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
if (length(x)!=0) {
pp[g, nlength] <- x
} else {  }
}
# get w i-1 count
m <- onelessgrams[grep(paste("^", chunk, "$", sep=""), onelessgrams$word), ]
n$prob <- n$freq/m$freq[1]
n$lastCount <- as.numeric(pp[,nlength])
# Kneser-Ney smoothing
delta <- 0.796
n
n$pKN <- (max(n$freq - delta, 0) / m$freq[1]) + (delta/m$freq[1]) * n$freq * ( n$lastCount / dim(bigrams)[1])
n
for (f in 1:length(n[,1])) {
n$pKN[f] <- (max(n$freq[f] - delta, 0) / m$freq[1]) + (delta/m$freq[1]) * n$freq[f] * ( n$lastCount[f] / dim(bigrams)[1])
}
n
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- jumble[order(-jumble$prob),]
winner <- jumble[1:(howMany*2), 1]
winner <- strsplit(winner, " ")
words <- NULL
howMany <- 1:5
jumble <- jumble[order(-jumble$prob),]
winner <- jumble[1:(howMany*2), 1]
winner <- strsplit(winner, " ")
words <- NULL
for (i in 1:length(winner)) {
lastWord <- winner[[i]][length(winner[[i]])]
words <- c(words, lastWord)
words <- unique(words)
}
words
source('~/Desktop/test.R', echo=TRUE)
source('~/Desktop/test.R', echo=TRUE)
source('~/Desktop/test.R', echo=TRUE)
input <- "Have you been to San"
mostLikely(input, 5)
mostLikely(input,2)
mostLikely(input,1)
m4 <- match(input, 4, quadgrams, trigrams)
input <- cleanInput(input)
if(length(input[[1]]) <= 1) {
return(0)
} else {
}
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$" }
nlength <- 2
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$" }
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
grams <- bigrams
onelessgrams <- unigrams
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
# get predicted word counts
predicted <- t(as.data.frame(strsplit(n$word, " ")))[,nlength]
pp <- cbind(predicted, rep(0, length(predicted)))
row.names(pp) <- NULL
for (g in 1:length(pp[,1])) {
x <- onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
if (length(x)!=0) {
pp[g, nlength] <- x
} else {  }
}
# get w i-1 count
m <- onelessgrams[grep(paste("^", chunk, "$", sep=""), onelessgrams$word), ]
n$prob <- n$freq/m$freq[1]
n$lastCount <- as.numeric(pp[,nlength])
# Kneser-Ney smoothing
delta <- 0.796
for (f in 1:length(n[,1])) {
n$pKN[f] <- (max(n$freq[f] - delta, 0) / m$freq[1]) + (delta/m$freq[1]) * n$freq[f] * ( n$lastCount[f] / dim(bigrams)[1])
}
return(n)
n
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4, m3, m2)
jumble <- m2
jumble <- jumble[order(-jumble$pKN),]
winner <- jumble[1:(howMany*2), 1]
howMany <- 2
jumble
nlength <- 3
grams <- trigrams
onelessgrams <- bigrams
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
input <- cleanInput(input)
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$" }
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
n
predicted <- t(as.data.frame(strsplit(n$word, " ")))[,nlength]
pp <- cbind(predicted, rep(0, length(predicted)))
row.names(pp) <- NULL
pp
for (g in 1:length(pp[,1])) {
x <- onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
if (length(x)!=0) {
pp[g, nlength] <- x
} else {  }
}
pp
g <- 1
x <- onelessgrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
x
)
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else if(nlength > 2) { start <- "" }
else { nlength2 <- 0; end <- "$"; start <- "$" }
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else if(nlength > 2) { start <- ""
} else { nlength2 <- 0; end <- "$"; start <- "$" }
start
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else if(nlength > 2) { begin <- ""
} else { nlength2 <- 0; end <- "$"; begin <- "$" }
begin
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else if(nlength > 2) { begin <- NULL
} else { nlength2 <- 0; end <- "$"; begin <- "$" }
begin
end
nlength2
if(nlength > 1 | nlength < 1) { nlength2 <- nlength -2; end <- "\\s"
} else if(nlength > 2) { begin <- NULL
} else { nlength2 <- 0; end <- "$"; begin <- "$" }
nlength
begin
end
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$"}
if(nlength > 2) begin <- NULL
if(nlength <= 2) begin <- "$"
x <- onelessgrams[grep(paste(begin, pp[g,nlength-1], "$", sep=""), onelessgrams$word), 2]
x
x <- unigrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), unigrams$word), 2]
pp
g <- 2
x <- unigrams[grep(paste("^", pp[g,nlength-1], "$", sep=""), unigrams$word), 2]
grep(paste("^", pp[g,nlength-1], "$", sep=""), unigrams$word)
paste("^", pp[g,nlength-1], "$", sep="")
pp[2,2]
x <- unigrams[grep(paste("^", pp[g,1], "$", sep=""), unigrams$word), 2]
source('~/.active-rstudio-document', echo=TRUE)
m2 <- match(input, 2, bigrams, unigrams)
m3 <- match(input, 3, trigrams, bigrams)
input <- cleanInput(input)
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$"}
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
n
predicted <- t(as.data.frame(strsplit(n$word, " ")))[,nlength]
pp <- cbind(predicted, rep(0, length(predicted)))
row.names(pp) <- NULL
for (g in 1:length(pp[,1])) {
x <- unigrams[grep(paste("^", pp[g,1], "$", sep=""), unigrams$word), 2]
if (length(x)!=0) {
pp[g, nlength] <- x
} else {  }
}
pp
for (g in 1:length(pp[,1])) {
x <- unigrams[grep(paste("^", pp[g,1], "$", sep=""), unigrams$word), 2]
if (length(x)!=0) {
pp[g, 2] <- x
} else {  }
}
pp
m <- onelessgrams[grep(paste("^", chunk, "$", sep=""), onelessgrams$word), ]
n$prob <- n$freq/m$freq[1]
n$lastCount <- as.numeric(pp[,nlength])
m <- onelessgrams[grep(paste("^", chunk, "$", sep=""), onelessgrams$word), ]
n$prob <- n$freq/m$freq[1]
n$lastCount <- as.numeric(pp[,2])
delta <- 0.796
for (f in 1:length(n[,1])) {
n$pKN[f] <- (max(n$freq[f] - delta, 0) / m$freq[1]) + (delta/m$freq[1]) * n$freq[f] * ( n$lastCount[f] / dim(bigrams)[1])
}
n
source('~/.active-rstudio-document', echo=TRUE)
m4 <- match(input, 4, quadgrams, trigrams)
m2 <- match(input, 2, bigrams, unigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2
m3
nlength <- 4
grams <- quadgrams
onelessgrams <- trigrams
input <- cleanInput(input)
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$"}
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
n
length(input[[1]]
)
length(n)
dim(n)[1]
source('~/Desktop/test.R', echo=TRUE)
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4, m3, m2)
jumble <- jumble[order(-jumble$pKN),]
winner <- jumble[1:(howMany*2), 1]
winner <- strsplit(winner, " ")
words <- NULL
for (i in 1:length(winner)) {
lastWord <- winner[[i]][length(winner[[i]])]
words <- c(words, lastWord)
words <- unique(words)
}
words
jumble
shiny::runApp('shiny')
mostLikley("Where in the world is", 3)
source('~/Desktop/test.R', echo=TRUE)
mostLikley("Where in the world is", 3)
mostLikely("Where in the world is", 3)
unigrams <- read.csv("compressed_freq/uniCompress.csv", stringsAsFactors=FALSE)
bigrams <- read.csv("compressed_freq/biCompress.csv", stringsAsFactors=FALSE)
trigrams <- read.csv("compressed_freq/triCompress.csv", stringsAsFactors=FALSE)
quadgrams <- read.csv("compressed_freq/quadCompress.csv", stringsAsFactors=FALSE)
cleanInput <- function(input) {
raw_input <- input
input <- tolower(raw_input)
input <- gsub("[^[:alpha:] ]", "", input)
input <- strsplit(input, " ")
return(input)
}
match <- function(input, nlength, grams, onelessgrams) {
input <- cleanInput(input)
if(length(input[[1]]) <= 1) {
return(0)
} else {
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$"}
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
if (dim(n)[1]!=0) {
# get predicted word counts
predicted <- t(as.data.frame(strsplit(n$word, " ")))[,nlength]
pp <- cbind(predicted, rep(0, length(predicted)))
row.names(pp) <- NULL
for (g in 1:length(pp[,1])) {
x <- unigrams[grep(paste("^", pp[g,1], "$", sep=""), unigrams$word), 2]
if (length(x)!=0) {
pp[g, 2] <- x
} else {  }
}
# get w i-1 count
m <- onelessgrams[grep(paste("^", chunk, "$", sep=""), onelessgrams$word), ]
n$prob <- n$freq/m$freq[1]
n$lastCount <- as.numeric(pp[,2])
# Kneser-Ney smoothing
delta <- 0.796
for (f in 1:length(n[,1])) {
n$pKN[f] <- (max(n$freq[f] - delta, 0) / m$freq[1]) + (delta/m$freq[1]) * n$freq[f] * ( n$lastCount[f] / dim(bigrams)[1])
}
}
return(n)
}
}
mostLikely <- function(input, howMany) {
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4, m3, m2)
if(dim(jumble)[1]==0) {
# handle unknown words or wrong words
return("I don't know that word, please try again.")
} else if (jumble[1,1]==0 ) {
# handle user putting in only one word
return("You'll need to enter at least 2 words.")
} else {
jumble <- jumble[order(-jumble$pKN),]
winner <- jumble[1:(howMany*2), 1]
winner <- strsplit(winner, " ")
words <- NULL
for (i in 1:length(winner)) {
lastWord <- winner[[i]][length(winner[[i]])]
words <- c(words, lastWord)
words <- unique(words)
}
return(words[howMany])
}
}
mostLikely("When are you going to San")
mostLikely("When are you going to San", 1)
mostLikely("When are you going to San", 3)
shiny::runApp('shiny')
mostLikely("I can't wait to", 1)
input <- "I can't wait to see"
shiny::runApp('shiny')
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4, m3, m2)
jumble
jumble <- jumble[order(-jumble$pKN),]
jumble
howMany <- 2
winner <- jumble[1:(howMany*2), 1]
winner <- strsplit(winner, " ")
words <- NULL
for (i in 1:length(winner)) {
lastWord <- winner[[i]][length(winner[[i]])]
words <- c(words, lastWord)
words <- unique(words)
}
return(words[howMany])
words
shiny::runApp('shiny')
input$text <- "how are you"
mostLikely("how are you", 1)
input <- "how are you"
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4, m3, m2)
jumble <- jumble[order(-jumble$pKN),]
head(jumble)
shiny::runApp('shiny')
source('~/Desktop/test.R')
shiny::runApp('shiny')
input <- "I can't wait to"
input <- cleanInput(input)
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
head(m2)
match <- function(input, nlength, grams, onelessgrams) {
input <- cleanInput(input)
if(length(input[[1]]) <= 1) {
return(0)
} else {
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$"}
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
n <- n[1:20,]
if (dim(n)[1]!=0) {
# get predicted word counts
predicted <- t(as.data.frame(strsplit(n$word, " ")))[,nlength]
pp <- cbind(predicted, rep(0, length(predicted)))
row.names(pp) <- NULL
for (g in 1:length(pp[,1])) {
x <- unigrams[grep(paste("^", pp[g,1], "$", sep=""), unigrams$word), 2]
if (length(x)!=0) {
pp[g, 2] <- x
} else {  }
}
# get w i-1 count
m <- onelessgrams[grep(paste("^", chunk, "$", sep=""), onelessgrams$word), ]
n$prob <- n$freq/m$freq[1]
n$lastCount <- as.numeric(pp[,2])
# Kneser-Ney smoothing
delta <- 0.796
for (f in 1:length(n[,1])) {
n$pKN[f] <- (max(n$freq[f] - delta, 0) / m$freq[1]) + (delta/m$freq[1]) * n$freq[f] * ( n$lastCount[f] / dim(bigrams)[1])
}
}
return(n)
}
}
m2 <- match(input, 2, bigrams, unigrams)
m2
shiny::runApp('shiny')
input <- "when can we go to San"
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
m3
shiny::runApp('shiny')
shiny::runApp('shiny')
