mod1 <- train(y~., method="rf", data=vowel.train)
varImp(mod1)
mod2 <- randomForest(y~., data=vowel.train)
varImp(mod2)
n <- varImp(mod2)
n <- n[order(n$Overall), ]
n
mod3 <- train(y~., method="rf", data=vowel.test)
varImp(mod3)
fancyRpartPlot(mod1$finalModel, cex=.6)
fancyRpartPlot(mod2$finalModel, cex=.6)
newsmedia <- data.frame(Month=c("November", "December", "January", "February", "March"), Pageviews=c(6307, 7960, 6612, 5987, 8913))
library(ggplot2)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge")
ggplot(newsmedia, aes(Month, Pageviews)) + geom_line()
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", aes(fill="steelblue"))
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue")
ggplot(newsmedia, aes(Month, Pageviews, ymax=1000)) + geom_bar(stat="identity", position="dodge", fill="steelblue")
ggplot(newsmedia, aes(Month, Pageviews, ymax=1200)) + geom_bar(stat="identity", position="dodge", fill="steelblue")
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + ylim(c(0, 1000))
newsmedia
str(newsmedia)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue")
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + ylim(c(0,1250))
?ylim
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month")
newsmedia$Month <- as.factor(newsmedia$Month, levels=newsmedia$Month)
newsmedia$Month <- factor(newsmedia$Month, levels=newsmedia$Month)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month")
newsmedia <- data.frame(Month=c("November", "December", "January", "February", "March"), Pageviews=c(6307, 7960, 6612, 5987, 8913))
newsmedia$Month <- factor(newsmedia$Month, levels=newsmedia$Month)
library(ggplot2)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month")
newsmedia <- data.frame(Month=c("November", "December", "January", "February", "March"), Pageviews=c(6307, 7960, 6612, 5987, 8913))
newsmedia$Month <- factor(newsmedia$Month, levels=newsmedia$Month)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month")
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0,1000))
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 1000))
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000))
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank())
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Prop), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
869+683+319+275+274
6307-2420
913+568
7961-(1053+913+568+555+476+467)
6162-(523+334+330+327+326)
5987-(666+511+348+299+285)
8913-(941+628+532+525+392)
rep(6, "November")
rep("November", 6)
nov <- data.frame(Story=c("College Celebrates Ring Delivery", "Concordia Theatre Presents Les Miserables", "Author Takes Winding Path to Success", "Finding the Global Perspective", "Hubbard Headlines Offutt Event", "Other"), Pageviews=c(869,683,319,275,274,3887), Month=rep("November", 6))
dec <- data.frame(Story=c("Celebrating a Concorida Christmas Tradition", "Christmas Concert Filled with Light", "Alumnus Research Becomes Personal", "They Came, They Saw, They Made History", "Concordia Great, Dr. Walther Prausnitz", "Other"), Pageviews=c(1053, 1481, 555, 476, 467, 3929), Month=rep("December", 6))
jan <- data.frame(Story=c("What's Complicated About Honoring King?", "Authors Announced for National Book Awards", "Short Documentary Gets International Recognition", "Grad Attends Top School for Public Health", "Play it Forward", "Other"), Pageviews=c(523,334,330,327,326,4332), Month=rep("January", 6))
feb <- data.frame(Story=c("The Singers Celebrate Clausen", "Concordia's Brainerd Concert is a Homecoming", "Kazoos at Concordia", "Formula for a Good Fit", "Wholly Concordia! Creating Connections", "Other"), Pageviews=c(666,511,348,299,285,3878), Month=rep("February", 6))
march <- data.frame(Story=c("Faculty Featured on TLC with Josh Groban", "Wholly Concordia! Better Business", "Spring Break 2015", "Getting Their Act Together", "Professor Featured on BBC","Other"), Pageviews=c(941,628,532,525,392,5895), Month=rep("March", 6))
months <- rbind(nov, dec, jan, feb, march)
months
ggplot(months, aes(Month, Pageviews)) + geom_bar(stat="identity", aes(fill=Story)) + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
nov <- data.frame(Story=c("College Celebrates Ring Delivery", "Concordia Theatre Presents Les Miserables", "Author Takes Winding Path to Success", "Finding the Global Perspective", "Hubbard Headlines Offutt Event", "Other"), Pageviews=c(869,683,319,275,274,3887), Month=rep("November", 6), Rank=c(1:6))
dec <- data.frame(Story=c("Celebrating a Concorida Christmas Tradition", "Christmas Concert Filled with Light", "Alumnus Research Becomes Personal", "They Came, They Saw, They Made History", "Concordia Great, Dr. Walther Prausnitz", "Other"), Pageviews=c(1053, 1481, 555, 476, 467, 3929), Month=rep("December", 6), Rank=c(1:6))
jan <- data.frame(Story=c("What's Complicated About Honoring King?", "Authors Announced for National Book Awards", "Short Documentary Gets International Recognition", "Grad Attends Top School for Public Health", "Play it Forward", "Other"), Pageviews=c(523,334,330,327,326,4332), Month=rep("January", 6), Rank=c(1:6))
feb <- data.frame(Story=c("The Singers Celebrate Clausen", "Concordia's Brainerd Concert is a Homecoming", "Kazoos at Concordia", "Formula for a Good Fit", "Wholly Concordia! Creating Connections", "Other"), Pageviews=c(666,511,348,299,285,3878), Month=rep("February", 6), Rank=c(1:6))
march <- data.frame(Story=c("Faculty Featured on TLC with Josh Groban", "Wholly Concordia! Better Business", "Spring Break 2015", "Getting Their Act Together", "Professor Featured on BBC","Other"), Pageviews=c(941,628,532,525,392,5895), Month=rep("March", 6), Rank=c(1:6))
months <- rbind(nov, dec, jan, feb, march)
ggplot(months, aes(Month, Pageviews)) + geom_bar(stat="identity", aes(fill=Rank)) + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
319+275+274+3887
3929+467+476+555
4332+326+327+330
3878+285+299+348
5895+392+525+532
# Top 2 Stories by Month
nov2 <- data.frame(Story=c("College Celebrates Ring Delivery", "Concordia Theatre Presents Les Miserables", "Other"), Pageviews=c(869,683,4755), Month=rep("November", 3), Rank=c(1:3))
dec2 <- data.frame(Story=c("Celebrating a Concorida Christmas Tradition", "Christmas Concert Filled with Light", "Other"), Pageviews=c(1053, 1481, 5427), Month=rep("December", 3), Rank=c(1:3))
jan2 <- data.frame(Story=c("What's Complicated About Honoring King?", "Authors Announced for National Book Awards",  "Other"), Pageviews=c(523,334,5315), Month=rep("January", 3), Rank=c(1:3))
feb2 <- data.frame(Story=c("The Singers Celebrate Clausen", "Concordia's Brainerd Concert is a Homecoming", "Other"), Pageviews=c(666,511,4810), Month=rep("February", 3), Rank=c(1:3))
march2 <- data.frame(Story=c("Faculty Featured on TLC with Josh Groban", "Wholly Concordia! Better Business", "Other"), Pageviews=c(941,628,7344), Month=rep("March", 3), Rank=c(1:3))
months2 <- rbind(nov2, dec2, jan2, feb2, march2)
ggplot(months2, aes(Month, Pageviews)) + geom_bar(stat="identity", aes(fill=Rank)) + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
# Top 2 Stories by Month
nov2 <- data.frame(Story=c("College Celebrates Ring Delivery", "Concordia Theatre Presents Les Miserables", "Other"), Pageviews=c(869,683,4755), Month=rep("November", 3), Rank=c(1:3))
dec2 <- data.frame(Story=c("Christmas Concert Filled with Light","Celebrating a Concorida Christmas Tradition",  "Other"), Pageviews=c(1481, 1053, 5427), Month=rep("December", 3), Rank=c(1:3))
jan2 <- data.frame(Story=c("What's Complicated About Honoring King?", "Authors Announced for National Book Awards",  "Other"), Pageviews=c(523,334,5315), Month=rep("January", 3), Rank=c(1:3))
feb2 <- data.frame(Story=c("The Singers Celebrate Clausen", "Concordia's Brainerd Concert is a Homecoming", "Other"), Pageviews=c(666,511,4810), Month=rep("February", 3), Rank=c(1:3))
march2 <- data.frame(Story=c("Faculty Featured on TLC with Josh Groban", "Wholly Concordia! Better Business", "Other"), Pageviews=c(941,628,7344), Month=rep("March", 3), Rank=c(1:3))
months2 <- rbind(nov2, dec2, jan2, feb2, march2)
ggplot(months2, aes(Month, Pageviews)) + geom_bar(stat="identity", aes(fill=Rank)) + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
+ geom_text(aes(label=Prop), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(months2, aes(Month, Pageviews)) + geom_bar(stat="identity", aes(fill=Rank)) + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank())
newsmedia <- data.frame(Month=c("November", "December", "January", "February", "March"), Pageviews=c(6307, 7960, 6162, 5987, 8913))
newsmedia$Month <- factor(newsmedia$Month, levels=newsmedia$Month)
#library(ggplot2)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="News & Media Pageviews") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
appurls <- data.frame(Month=c("November", "December", "January", "February", "March"), Pageviews=c(497, 592,497,503,367))
appurls$Month <- factor(appurls$Month, levels=appurls$Month)
#library(ggplot2)
ggplot(appurls, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="News & Media Pageviews") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(appurls, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="News & Media Pageviews") + ylim(c(0, 750)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(appurls, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Unique Application URL Pageviews") + ylim(c(0, 750)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
source('~/.active-rstudio-document')
homepage <- data.frame(Month=c("November", "December", "January", "February", "March", "April"), Pageviews=c(55506, 42495,53938,51982,52050,50616))
homepage$Month <- factor(homepage$Month, levels=homepage$Month)
#library(ggplot2)
ggplot(homepage, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Homepage Pageviews") + ylim(c(0, 750)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
library(ggplot2)
ggplot(homepage, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Homepage Pageviews") + ylim(c(0, 750)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(homepage, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Homepage Pageviews") + ylim(c(0, 75000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(homepage, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Homepage Pageviews") + ylim(c(0, 65000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
getwd()
library("ggplot2")
rates <- data.frame(Percent=c(.6176,.9396,.3634,.5331,.2697,.1686,.1211,.0889), Rate=c(rep("open rate",4), rep("click to open rate",4)), Group=c(rep(c("deposit cobberlife", "deposit overall", "admit cobberlife", "admit overall"), 4)))
View(rates)
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Rate))
rates <- data.frame(Percent=c(.6176,.9396,.3634,.5331,.2697,.1686,.1211,.0889), Rate=c(rep("open rate",4), rep("click to open rate",4)), Group=c(rep(c("deposit", "deposit", "admit", "admit"), 4)), Send=c(rep(c("cobberlife", "overall"), 8))
View(rates)
rates <- data.frame(Percent=c(.6176,.9396,.3634,.5331,.2697,.1686,.1211,.0889), Rate=c(rep("open rate",4), rep("click to open rate",4)), Group=c(rep(c("deposit", "deposit", "admit", "admit"), 4)), Send=c(rep(c("cobberlife", "overall"), 8)))
View(rates)
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Rate))
rates$Combo <- paste(rates$Rate, rates$Send)
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Combo))
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Combo)) + scale_fill_brewer(palette="Paired")
rates <- data.frame(Percent=c(.6176,.9396,.3634,.5331,.2697,.1686,.1211,.0889), Rate=c(rep("open rate",4), rep("click to open rate",4)), Group=c(rep(c("deposit", "deposit", "admit", "admit"), 4)), Send=c(rep(c("cobberlife", "overall"), 8)))
rates$Combo <- paste(rates$Rate, rates$Group)
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Combo)) + scale_fill_brewer(palette="Paired")
View(rates)
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Group)) + scale_fill_brewer(palette="Paired")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank()) + labs("CobberLife vs. Overall Rates", y="Percent", x="")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1)) + labs("CobberLife vs. Overall Rates", y="Percent", x="")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank(), axis.text.x = element_text(angle = 15, hjust = 1)) + labs("CobberLife vs. Overall Rates", y="Percent", x="")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank(), axis.text.x = element_text(angle = 15, hjust = 1)) + labs(title="CobberLife vs. Overall Rates", y="Percent", x="")
getwd()
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank(), axis.text.x = element_text(angle = 15, hjust = 1)) + labs(title="CobberLife vs. Overall Rates", y="Percent", x="") + geom_text(aes(label=Percent)
)
getwd()
setwd()~
)
setwd(~/)
setwd(~)
setwd("~")
getwd()
news <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/US_en.news.sample.txt", stringsAsFactors=FALSE)
news <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.news.sample.txt", stringsAsFactors=FALSE)
twitter <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.twitter.sample.txt", stringsAsFactors=FALSE)
blog <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.blog.sample.txt", stringsAsFactors=FALSE)
install.packages("tm")
install.packages("RWeka")
library("knitr")
library("tm")
library("RWeka")
hist(nchar(news))
unique(blog[1:100],)
unique(blog[1:10,])
unique(twitter[1:10,])
strsplit(twitter[1:10,], " ")
test <- strsplit(twitter[1:5,], " ")
test
corpusT = Corpus(VectorSource(twitter[1:10,]))
corpusT
corpusT <- tm_map(corpusT, tolower)
corpusT <- tm_map(corpusT, PlainTextDocument)
corpusT <- tm_map(corpusT, removePunctuation)
corpusT
summary(corpusT)
corpusT <- tm_map(corpusT, removeWords, stopwords("english"))
corpusT <- tm_map(corpusT, stemDocument)
corpusT = Corpus(VectorSource(twitter[1:10,]))
corpusT <- tm_map(corpusT, tolower)
corpusT <- tm_map(corpusT, PlainTextDocument)
corpusT <- tm_map(corpusT, removePunctuation)
corpusT <- tm_map(corpusT, stemDocument)
?tm_map
test <- twitter[1:10,]
test
test <- paste(test, collapse=" ")
test
test <- twitter[1:10,]
nchar(test)
test <- paste(test, collapse=" ")
nchar(test)
test <- strsplit(test, "?|!|.")
rest
test
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\?|\\!|\\.")
test
test <- strsplit(test, "\\? |\\! |\\. ")
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\? |\\! |\\. ")
test
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\? |\\?? |\\! |\\!! |\\. ")
test
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\? |\\! |\\. ")
test
test <- twitter[1:10,]
test
test <- paste(test, collapse=" ")
test
test <- strsplit(test, "\\?+ |\\!+ |\\.+ ")
test
test <- twitter[1:10,]
test <- strsplit(test, "\\?+ |\\!+ |\\.+ ")
test
test <- paste(test, collapse=" ")
test
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test
test <- strsplit(test, "\\?+ |\\!+ |\\.+ ")
test
library("knitr")
library("tm")
library("RWeka")
library("plyr")
library("ggplot2")
library("gridExtra")
library("SnowballC")
opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE, fig.height=4, fig.width=4, echo=FALSE)
news <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.news.sample.txt", stringsAsFactors=FALSE)
twitter <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.twitter.sample.txt", stringsAsFactors=FALSE)
blog <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.blog.sample.txt", stringsAsFactors=FALSE)
#news<-iconv(t, to="ASCII", sub = "")
#news <- read.table("/Users/kaylinwalker/R/DS_Capstone/data/en_US.news.sample.txt", stringsAsFactors=FALSE)
#twitter <- read.table("/Users/kaylinwalker/R/DS_Capstone/data/en_US.twitter.sample.txt", stringsAsFactors=FALSE)
#blog <- read.table("/Users/kaylinwalker/R/DS_Capstone/data/en_US.blog.sample.txt", stringsAsFactors=FALSE)
newsTT <- WordTokenizer(unlist(news))
twitterTT <- WordTokenizer(unlist(twitter))
blogTT <- WordTokenizer(unlist(blog))
avgChar <- function (x) round(sum(nchar(unlist(x)))/dim(x)[1],0)
avgTokens  <- function (x,y) round(length(y)/dim(x)[1],0)
wordTable <- data.frame(
Corpus=c("News 5% Sample", "Twitter 5% Sample", "Blog 5% Sample"),
Lines=c(dim(news)[1], dim(twitter)[1], dim(blog)[1]),
Avg.Char.Line=c(avgChar(news), avgChar(twitter), avgChar(blog)),
Avg.Tokens.Line=c(avgTokens(news, newsTT), avgTokens(twitter, twitterTT), avgTokens(blog, blogTT)),
Total.Tokens=c(length(newsTT), length(twitterTT), length(blogTT)),
Unique.Tokens=c(length(unique(newsTT)), length(unique(twitterTT)), length(unique(blogTT)))
)
kable(wordTable, row.names=FALSE)
setwd("/Users/kwalker/git_projects/DS_Capstone/")
corpus <- Corpus(DirSource("data"), readerControl=list(language="en"))
library("knitr")
library("tm")
library("RWeka")
library("plyr")
library("ggplot2")
library("gridExtra")
library("SnowballC")
opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE, fig.height=4, fig.width=4, echo=FALSE)
setwd("/Users/kwalker/git_projects/DS_Capstone/")
#setwd("/Users/kaylinwalker/R/DS_Capstone")
corpus <- Corpus(DirSource("data"), readerControl=list(language="en"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
options(mc.cores=1)
unis <- function(x) WordTokenizer(x)
unis <- TermDocumentMatrix(corpus, control=list(tokenize=unis))
freqFunc <- function(corpus) {
terms <- findFreqTerms(corpus, lowfreq = 5)
table <- rowSums(as.matrix(corpus[terms,]))
table <- data.frame(word=names(table), freq=table)
table <- table[order(-table$freq), ]
table$rank <- 1:length(table[,1])
return(table)
}
n <- freqFunc(unis)
head(n, 10)
head(n, 30)
unigrams <- function(x) NGramTokenizer(x, Weka_control(min=0, max=1))
uniCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = unigrams, wordLengths=c(1,Inf)))
freqUni <- freqFunc(uniCorpus)
head(freqUni, 20)
library("knitr")
library("tm")
library("RWeka")
library("plyr")
library("ggplot2")
library("gridExtra")
library("SnowballC")
opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE, fig.height=4, fig.width=4, echo=FALSE)
news <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.news.sample3.txt", stringsAsFactors=FALSE)
twitter <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.twitter.sample3.txt", stringsAsFactors=FALSE)
blog <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.blog.sample3.txt", stringsAsFactors=FALSE)
#news <- read.table("/Users/kaylinwalker/R/DS_Capstone/data/en_US.news.sample3.txt", stringsAsFactors=FALSE)
#twitter <- read.table("/Users/kaylinwalker/R/DS_Capstone/data/en_US.twitter.sample3.txt", stringsAsFactors=FALSE)
#blog <- read.table("/Users/kaylinwalker/R/DS_Capstone/data/en_US.blog.sample3.txt", stringsAsFactors=FALSE)
allSamples <- rbind(news, twitter, blog)
#write.csv(allSamples,"allSamples.csv", row.names=FALSE)
setwd("/Users/kwalker/git_projects/DS_Capstone/")
#setwd("/Users/kaylinwalker/R/DS_Capstone")
corpus <- Corpus(DirSource("data"), readerControl=list(language="en"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
#writeCorpus(corpus, path=".", filenames=paste(seq_along(corpus)))
options(mc.cores=1)
unigrams <- function(x) NGramTokenizer(x, Weka_control(min=0, max=1))
bigrams <- function(x) NGramTokenizer(x, Weka_control(min=2, max=2))
trigrams <- function(x) NGramTokenizer(x, Weka_control(min=3, max=3))
quadgrams <- function(x) NGramTokenizer(x, Weka_control(min=4, max=4))
#allgrams <- function(x) NGramTokenizer(x, Weka_control(min=2, max=4))
uniCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = unigrams, wordLengths=c(1,Inf)))
biCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = bigrams), wordLengths=c(1,Inf))
triCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = trigrams), wordLengths=c(1,Inf))
quadCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = quadgrams), wordLengths=c(1,Inf))
#allCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = allgrams))
freqUni <- freqFunc(uniCorpus)
freqBi <- freqFunc(biCorpus)
freqUni[1:10, c(3,1,2) ]
hist(log10(freqUni$freq),  main="Log10 Uni-gram Frequency")
freqUni$Sum <- cumsum(freqUni$freq)
uni50 <- subset(freqUni, freqUni$Sum >  sum(freqUni$freq)*0.5) #266
uni90 <- subset(freqUni, freqUni$Sum >  sum(freqUni$freq)*0.9)
compressFunc <- function(fTable, fCorpus) {
fTable$Sum <- cumsum(fTable$freq)
majority <- subset(fTable, fTable$Sum >  sum(fTable$freq)*0.9)
cutoff <- majority[1,3]
dictionary <- fTable[fTable$rank < cutoff, 1]
dictionary <- as.character(unlist(dictionary))
compress <- rowSums(as.matrix(fCorpus[dictionary,]))
compress <- data.frame(word=dictionary, freq=compress)
}
uniCompress <- compressFunc(freqUni, uniCorpus)
head(uniCompress, 25)
write.csv(uniCompress, "uniCompress.csv", row.names=FALSE)
unigrams <- read.csv("compressed_freq/uniCompress.csv", stringsAsFactors=FALSE)
raw_input <- "I am going to"
input <- tolower(raw_input)
input <- gsub("[^[:alpha:] ]", "", input)
input <- strsplit(input, " ")
match <- function(input, nlength, grams, onelessgrams) {
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$" }
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
m <- onelessgrams[grep(paste("^", chunk, "$", sep=""), onelessgrams$word), ]
n$prob <- n$freq/m$freq[1]
return(n)
}
m4 <- match(input, 4, quadgrams, trigrams)
head(uniCompress)
raw_input <- "I am going to"
input <- tolower(raw_input)
input <- gsub("[^[:alpha:] ]", "", input)
input <- strsplit(input, " ")
nlength <- 2
grams <- bigrams
grams <- unigrams
grams <- bigrams
onelessgrams <- unigrams
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$" }
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
head(grams)
unigrams <- read.csv("compressed_freq/uniCompress.csv", stringsAsFactors=FALSE)
bigrams <- read.csv("compressed_freq/biCompress.csv", stringsAsFactors=FALSE)
trigrams <- read.csv("compressed_freq/triCompress.csv", stringsAsFactors=FALSE)
quadgrams <- read.csv("compressed_freq/quadCompress.csv", stringsAsFactors=FALSE)
m2 <- match(input, 2, bigrams, unigrams)
head(m2)
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m4
head(m3)
jumble <- rbind(m4[1,], m3[1,], m2[1,])
jumble
jumble <- jumble[-order(jumble$prob),]
jumble
jumble <- rbind(m4[1,], m3[1,], m2[1,])
jumble <- jumble[order(-jumble$prob),]
jumble
cleanInput <- function(x) {
raw_input <- x
input <- tolower(raw_input)
input <- gsub("[^[:alpha:] ]", "", input)
input <- strsplit(input, " ")
return(input)
}
cleanInput("I am g8oing to")
match <- function(input, nlength, grams, onelessgrams) {
input <- cleanInput(input)
if(nlength != 1) { nlength2 <- nlength -2; end <- "\\s"
} else { nlength2 <- 0; end <- "$" }
chunk <- input[[1]][ (length(input[[1]])-nlength2):length(input[[1]]) ]
chunk <- paste(chunk, collapse=" ")
chunk <- gsub("^\\s+|\\s+$", "", chunk)
n <- grams[grep(paste("^", chunk, end, sep=""), grams$word), ]
m <- onelessgrams[grep(paste("^", chunk, "$", sep=""), onelessgrams$word), ]
n$prob <- n$freq/m$freq[1]
return(n)
}
m4 <- match(input, 4, quadgrams, trigrams)
m4
mostLikely <- function(input) {
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4[1,], m3[1,], m2[1,])
jumble <- jumble[order(-jumble$prob),]
winner <- jumble[1,1]
return(winner)
}
mostLikely("I am g8oing to")
mostLikely("when are you")
input <- "when is"
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4[1,], m3[1,], m2[1,])
jumble <- jumble[order(-jumble$prob),]
winner <- jumble[1,1]
winner
winner <- strsplit(winner, " ")
winner
winner[1[1]]
winner[[1]]
winner[[1]][length(winner[[1]])]
winner <- winner[[1]][length(winner[[1]])]
return(winner)
mostLikely <- function(input) {
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4[1,], m3[1,], m2[1,])
jumble <- jumble[order(-jumble$prob),]
winner <- jumble[1,1]
winner <- strsplit(winner, " ")
winner <- winner[[1]][length(winner[[1]])]
return(winner)
}
mostLikely("when are you")
mostLikely("when are you going to the")
mostLikely("I have a lovely bunch of")
mostLikely("I have a")
mostLikely("I have a lovely")
mostLikely("what in the")
mostLikely("you are such an")
mostLikely("i hate")
mostLikely("you")
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4[5,], m3[5,], m2[5,])
jumble <- jumble[order(-jumble$prob),]
jumble
input <- "i hate"
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4[5,], m3[5,], m2[5,])
jumble <- jumble[order(-jumble$prob),]
jumble
freqQuad[1:10, 1:2]
head(uni50)
head(uni90)
object.size(match)
object.size(mostLikely)
object.size(cleanInput)
object.size(quadgrams)
View(uniCompress)
source('~/.active-rstudio-document')
runApp("shiny")
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4[5,], m3[5,], m2[5,])
jumble <- jumble[order(-jumble$prob),]
jumble
input <- "Where is the"
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4[5,], m3[5,], m2[5,])
jumble <- jumble[order(-jumble$prob),]
jumble
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
head(m3)
m4 <- match(input, 4, quadgrams, trigrams)
m3 <- match(input, 3, trigrams, bigrams)
m2 <- match(input, 2, bigrams, unigrams)
jumble <- rbind(m4[1:5,], m3[1:5,], m2[1:5,])
jumble <- jumble[order(-jumble$prob),]
jumble
jumble <- rbind(m4, m3, m2)
jumble
head(jumble)
winner <- jumble[1:10,1]
winner
winner <- strsplit(winner, " ")
winner
winner <- jumble[1,1]
winner <- strsplit(winner, " ")
winner <- winner[[1]][length(winner[[1]])]
return(winner)
winner
shiny::runApp('shiny')
