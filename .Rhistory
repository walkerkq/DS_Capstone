nov2 <- data.frame(Story=c("College Celebrates Ring Delivery", "Concordia Theatre Presents Les Miserables", "Other"), Pageviews=c(869,683,4755), Month=rep("November", 3), Rank=c(1:3))
dec2 <- data.frame(Story=c("Celebrating a Concorida Christmas Tradition", "Christmas Concert Filled with Light", "Other"), Pageviews=c(1053, 1481, 5427), Month=rep("December", 3), Rank=c(1:3))
jan2 <- data.frame(Story=c("What's Complicated About Honoring King?", "Authors Announced for National Book Awards",  "Other"), Pageviews=c(523,334,5315), Month=rep("January", 3), Rank=c(1:3))
feb2 <- data.frame(Story=c("The Singers Celebrate Clausen", "Concordia's Brainerd Concert is a Homecoming", "Other"), Pageviews=c(666,511,4810), Month=rep("February", 3), Rank=c(1:3))
march2 <- data.frame(Story=c("Faculty Featured on TLC with Josh Groban", "Wholly Concordia! Better Business", "Other"), Pageviews=c(941,628,7344), Month=rep("March", 3), Rank=c(1:3))
months2 <- rbind(nov2, dec2, jan2, feb2, march2)
ggplot(months2, aes(Month, Pageviews)) + geom_bar(stat="identity", aes(fill=Rank)) + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
# Top 2 Stories by Month
nov2 <- data.frame(Story=c("College Celebrates Ring Delivery", "Concordia Theatre Presents Les Miserables", "Other"), Pageviews=c(869,683,4755), Month=rep("November", 3), Rank=c(1:3))
dec2 <- data.frame(Story=c("Christmas Concert Filled with Light","Celebrating a Concorida Christmas Tradition",  "Other"), Pageviews=c(1481, 1053, 5427), Month=rep("December", 3), Rank=c(1:3))
jan2 <- data.frame(Story=c("What's Complicated About Honoring King?", "Authors Announced for National Book Awards",  "Other"), Pageviews=c(523,334,5315), Month=rep("January", 3), Rank=c(1:3))
feb2 <- data.frame(Story=c("The Singers Celebrate Clausen", "Concordia's Brainerd Concert is a Homecoming", "Other"), Pageviews=c(666,511,4810), Month=rep("February", 3), Rank=c(1:3))
march2 <- data.frame(Story=c("Faculty Featured on TLC with Josh Groban", "Wholly Concordia! Better Business", "Other"), Pageviews=c(941,628,7344), Month=rep("March", 3), Rank=c(1:3))
months2 <- rbind(nov2, dec2, jan2, feb2, march2)
ggplot(months2, aes(Month, Pageviews)) + geom_bar(stat="identity", aes(fill=Rank)) + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
+ geom_text(aes(label=Prop), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(months2, aes(Month, Pageviews)) + geom_bar(stat="identity", aes(fill=Rank)) + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank())
newsmedia <- data.frame(Month=c("November", "December", "January", "February", "March"), Pageviews=c(6307, 7960, 6162, 5987, 8913))
newsmedia$Month <- factor(newsmedia$Month, levels=newsmedia$Month)
#library(ggplot2)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Pageviews to all News and Media pages by month") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(newsmedia, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="News & Media Pageviews") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
appurls <- data.frame(Month=c("November", "December", "January", "February", "March"), Pageviews=c(497, 592,497,503,367))
appurls$Month <- factor(appurls$Month, levels=appurls$Month)
#library(ggplot2)
ggplot(appurls, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="News & Media Pageviews") + ylim(c(0, 10000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(appurls, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="News & Media Pageviews") + ylim(c(0, 750)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(appurls, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Unique Application URL Pageviews") + ylim(c(0, 750)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
source('~/.active-rstudio-document')
homepage <- data.frame(Month=c("November", "December", "January", "February", "March", "April"), Pageviews=c(55506, 42495,53938,51982,52050,50616))
homepage$Month <- factor(homepage$Month, levels=homepage$Month)
#library(ggplot2)
ggplot(homepage, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Homepage Pageviews") + ylim(c(0, 750)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
library(ggplot2)
ggplot(homepage, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Homepage Pageviews") + ylim(c(0, 750)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(homepage, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Homepage Pageviews") + ylim(c(0, 75000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
ggplot(homepage, aes(Month, Pageviews)) + geom_bar(stat="identity", position="dodge", fill="steelblue") + labs(title="Homepage Pageviews") + ylim(c(0, 65000)) + theme(panel.background = element_blank()) + geom_text(aes(label=Pageviews), size=4, position=position_dodge(width=1), vjust=-.5)
getwd()
library("ggplot2")
rates <- data.frame(Percent=c(.6176,.9396,.3634,.5331,.2697,.1686,.1211,.0889), Rate=c(rep("open rate",4), rep("click to open rate",4)), Group=c(rep(c("deposit cobberlife", "deposit overall", "admit cobberlife", "admit overall"), 4)))
View(rates)
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Rate))
rates <- data.frame(Percent=c(.6176,.9396,.3634,.5331,.2697,.1686,.1211,.0889), Rate=c(rep("open rate",4), rep("click to open rate",4)), Group=c(rep(c("deposit", "deposit", "admit", "admit"), 4)), Send=c(rep(c("cobberlife", "overall"), 8))
View(rates)
rates <- data.frame(Percent=c(.6176,.9396,.3634,.5331,.2697,.1686,.1211,.0889), Rate=c(rep("open rate",4), rep("click to open rate",4)), Group=c(rep(c("deposit", "deposit", "admit", "admit"), 4)), Send=c(rep(c("cobberlife", "overall"), 8)))
View(rates)
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Rate))
rates$Combo <- paste(rates$Rate, rates$Send)
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Combo))
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Combo)) + scale_fill_brewer(palette="Paired")
rates <- data.frame(Percent=c(.6176,.9396,.3634,.5331,.2697,.1686,.1211,.0889), Rate=c(rep("open rate",4), rep("click to open rate",4)), Group=c(rep(c("deposit", "deposit", "admit", "admit"), 4)), Send=c(rep(c("cobberlife", "overall"), 8)))
rates$Combo <- paste(rates$Rate, rates$Group)
ggplot(rates, aes(Group, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Combo)) + scale_fill_brewer(palette="Paired")
View(rates)
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Group)) + scale_fill_brewer(palette="Paired")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank()) + labs("CobberLife vs. Overall Rates", y="Percent", x="")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1)) + labs("CobberLife vs. Overall Rates", y="Percent", x="")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank(), axis.text.x = element_text(angle = 15, hjust = 1)) + labs("CobberLife vs. Overall Rates", y="Percent", x="")
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank(), axis.text.x = element_text(angle = 15, hjust = 1)) + labs(title="CobberLife vs. Overall Rates", y="Percent", x="")
getwd()
ggplot(rates, aes(Combo, Percent)) + geom_bar(stat="identity", position="dodge", aes(fill=Send)) + scale_fill_brewer(palette="Paired") + theme(panel.background = element_blank(), axis.text.x = element_text(angle = 15, hjust = 1)) + labs(title="CobberLife vs. Overall Rates", y="Percent", x="") + geom_text(aes(label=Percent)
)
getwd()
setwd()~
)
setwd(~/)
setwd(~)
setwd("~")
getwd()
news <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/US_en.news.sample.txt", stringsAsFactors=FALSE)
news <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.news.sample.txt", stringsAsFactors=FALSE)
twitter <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.twitter.sample.txt", stringsAsFactors=FALSE)
blog <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.blog.sample.txt", stringsAsFactors=FALSE)
install.packages("tm")
install.packages("RWeka")
library("knitr")
library("tm")
library("RWeka")
hist(nchar(news))
unique(blog[1:100],)
unique(blog[1:10,])
unique(twitter[1:10,])
strsplit(twitter[1:10,], " ")
test <- strsplit(twitter[1:5,], " ")
test
corpusT = Corpus(VectorSource(twitter[1:10,]))
corpusT
corpusT <- tm_map(corpusT, tolower)
corpusT <- tm_map(corpusT, PlainTextDocument)
corpusT <- tm_map(corpusT, removePunctuation)
corpusT
summary(corpusT)
corpusT <- tm_map(corpusT, removeWords, stopwords("english"))
corpusT <- tm_map(corpusT, stemDocument)
corpusT = Corpus(VectorSource(twitter[1:10,]))
corpusT <- tm_map(corpusT, tolower)
corpusT <- tm_map(corpusT, PlainTextDocument)
corpusT <- tm_map(corpusT, removePunctuation)
corpusT <- tm_map(corpusT, stemDocument)
?tm_map
test <- twitter[1:10,]
test
test <- paste(test, collapse=" ")
test
test <- twitter[1:10,]
nchar(test)
test <- paste(test, collapse=" ")
nchar(test)
test <- strsplit(test, "?|!|.")
rest
test
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\?|\\!|\\.")
test
test <- strsplit(test, "\\? |\\! |\\. ")
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\? |\\! |\\. ")
test
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\? |\\?? |\\! |\\!! |\\. ")
test
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\? |\\! |\\. ")
test
test <- twitter[1:10,]
test
test <- paste(test, collapse=" ")
test
test <- strsplit(test, "\\?+ |\\!+ |\\.+ ")
test
test <- twitter[1:10,]
test <- strsplit(test, "\\?+ |\\!+ |\\.+ ")
test
test <- paste(test, collapse=" ")
test
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test
test <- strsplit(test, "\\?+ |\\!+ |\\.+ ")
test
?system.file
setwd("/Users/kwalker/git_projects/DS_Capstone/data")
a <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/data"), readControl=list(language="lat"))
library("tm")
a <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/data"), readControl=list(language="lat"))
a <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/data"), readerControl=list(language="lat"))
summary(a)
corpus <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/data"), readerControl=list(language="lat"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, tolower)
corpusDTM <- DocumentTermMatrix(corpus)
corpus <- tm_map(corpus, stemDocument)
corpus <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/data"), readerControl=list(language="lat"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, stemDocument)
corpusDTM <- DocumentTermMatrix(corpus)
corpus <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/data"), readerControl=list(language="lat"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
install.packages("SnowballC")
library("SnowballC")
corpusDTM <- DocumentTermMatrix(corpus)
inspect(corpusDTM)
inspect(corpusDTM[1:2])
print(corpusDTM)
inspect(corpusDTM[5:10, 700:705])
findFreqTerms(corpusDTM, 5)
findFreqTerms(corpusDTM, 100)
findFreqTerms(corpusDTM, 10000)
findAssocs(corpusDTM, "walmart", 0.8)
findAssocs(corpusDTM, "walmart", 0.95)
findAssocs(corpusDTM, "walmart", 0.999)
inspect(DocumentTermMatrix(corpusDTM, list(dictionary=c("prices", "crude", "oil"))))
inspect(corpusDTM, list(dictionary=c("prices", "crude", "oil")))
inspect(corpusDTM, list(dictionary = c("prices", "crude", "oil")))
?list
?inspect
inspect(corpusDTM)
head(corpus)
corpus <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/testdata"), readerControl=list(language="lat"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
corpusDTM2 <- DocumentTermMatrix(corpus)
inspect(corpusDTM2)
print(corpusDTM2)
bigrams <- function(x) NGramTokenizer(x, Weka_control(min=2, max=2))
tdm <- DocumentTermMatrix(corpus, control=list(tokenize= bigrams, wordlengths = c(0, Inf)))
tdm <- DocumentTermMatrix(corpus, control=list(tokenize= bigrams))
library("SnowballC")
tdm <- DocumentTermMatrix(corpus, control=list(tokenize= bigrams))
corpus <- Corpus(VectorSource(corpus))
tdm <- DocumentTermMatrix(corpus, control=list(tokenize= bigrams))
corpus <- iconv(corpus, to = "utf-8", sub="")
tdm <- DocumentTermMatrix(corpus, control=list(tokenize= bigrams))
setwd("/Users/kwalker/git_projects/DS_Capstone/")
corpus <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/testdata"), readerControl=list(language="lat"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
options(mc.cores=1)
tdm <- DocumentTermMatrix(corpus, control=list(tokenize= bigrams))
library("RWeka")
tdm <- DocumentTermMatrix(corpus, control=list(tokenize = bigrams))
tdm
inspect(tdm)
tdm <- TermDocumentMatrix(corpus, control=list(tokenize = bigrams))
inspect(tdm)
dim(tdm)
setwd("/Users/kwalker/git_projects/DS_Capstone/")
corpus <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/testdata"), readerControl=list(language="lat"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, stemDocument)
corpus <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/testdata"), readerControl=list(language="en"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, stemDocument)
bigrams <- function(x) NGramTokenizer(x, Weka_control(min=2, max=2))
options(mc.cores=1)
tdm <- TermDocumentMatrix(corpus, control=list(tokenize = bigrams))
dim(tdm)
inspect(tdm[1:100,])
findAssocs(tdm, "voldemort", .9)
findAssocs(tdm, "voldemort", .8)
findAssocs(tdm, "adapt", .8)
findAssocs(tdm, "adapt of", .8)
bigrams <- function(x) NGramTokenizer(x, Weka_control(min=1, max=2))
tdm <- TermDocumentMatrix(corpus, control=list(tokenize = bigrams))
findAssocs(tdm, "voldemort", .8)
findAssocs(tdm, "voldemort", .95)
findAssocs(tdm, "voldemort", 1)
findAssocs(tdm, "voldemort", .99)
inspect(tdm, 1:10)
inspect(tdm[1:10,])
n <- tdm[order(tdm$HP1, decreasing=TRUE),]
file.info(/Users/kwalker/git_projects/DS_Capstone/data/en_US.news.sample.txt)
file.info("/Users/kwalker/git_projects/DS_Capstone/data/en_US.news.sample.txt")
func_gram <- function(x) {
tkzr <- function (x) NGramTokenizer(x, Weka_control(min=x, max=x))
func_tdm <- TermDocumentMatrix(cleanCorpus, control=list(tokenize=tkzr))
return(func_tdm)
}
options(mc.cores=1)
func_gram <- function(x) {
tkzr <- function (x) NGramTokenizer(x, Weka_control(min=x, max=x))
func_tdm <- TermDocumentMatrix(corpus, control=list(tokenize=tkzr))
return(func_tdm)
}
corpus <- Corpus(DirSource("/Users/kwalker/git_Projects/DS_Capstone/testdata"), readerControl=list(language="en"))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
func_gram(1)
bigrams <- function(x) NGramTokenizer(x, Weka_control(min=1, max=2))
options(mc.cores=1)
tdm <- TermDocumentMatrix(corpus, control=list(tokenize = bigrams))
bigrams <- function(x) NGramTokenizer(x, Weka_control(min=2, max=2))
options(mc.cores=1)
tdm <- TermDocumentMatrix(corpus, control=list(tokenize = bigrams))
head(tdm)
inspect(tdm[1:10,])
m <- as.matrix(tdm)
head(m)
v <- sort(rowSums(m), decreasing=TRUE)
head(v)
tkzr <- function(x, ng) NGramTokenizer(x, Weka_control(min=ng, max=ng))
tdm <- TermDocumentMatrix(corpus, control=list(tokenize = tkzr(corpus, 2)))
tdm <- TermDocumentMatrix(corpus, control=list(tokenize = tkzr(2)))
bi.corpus <- TermDocumentMatrix(corpus, control=list(tokenize = bigrams))
biCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = bigrams))
biCorpusM <- matrix(biCorpus)
head(biCorpusM)
inspect(biCorpus[1:10,])
biCorpusM <- as.matrix(biCorpus)
head(biCorpusM)
biCorpusM$Sum <- rowSums(biCorpusM)
biCorpusRank <- sort(rowSums(biCorpusM), decreasing=TRUE)
biCorpusM <- as.matrix(biCorpus)
biCorpusRank <- sort(rowSums(biCorpusM), decreasing=TRUE)
head(biCorpusRank)
biCorpusM <- as.data.frame(biCorpus)
str(biCorpusRank)
x<-data.frame(biCorpusRank)
head(x)
biCorpusRank <- data.frame(sort(rowSums(biCorpusM), decreasing=TRUE))
head(biCorpusRank)
biCorpusRank$Rank <- 1:length(biCorpusRank[1,])
head(biCorpusRank)
biCorpusRank$Rank <- 1:length(biCorpusRank[,1])
head(biCorpusRank)
triCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = trigrams))
trigrams <- function(x) NGramTokenizer(x, Weka_control(min=3, max=3))
triCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = trigrams))
triCorpusM <- as.matrix(triiCorpus)
triCorpusM <- as.matrix(triCorpus)
triCorpusRank <- data.frame(sort(rowSums(triCorpusM), decreasing=TRUE))
triCorpusRank$Rank <- 1:length(triCorpusRank[,1])
head(triCorpusRank)
unigrams <- function(x) NGramTokenizer(x, Weka_control(min=1, max=1))
uniCorpus <- TermDocumentMatrix(corpus, control=list(tokenize = unigrams))
inspect(uniCorpus[1:10,])
uniCorpusM <- as.matrix(uniCorpus)
head(uniCorpusM)
str(uniCorpusM)
n <- as.data.frame(uniCorpusM)
str(uniCorpusM)
n <- data.frame(uniCorpusM)
str(uniCorpusM)
freqTerms <- findFreqTerms(corpus, lowfreq = 50)
freqTerms <- findFreqTerms(uniCorpus, lowfreq = 50)
freq <- rowSums(as.matrix(uniCorpus[freqTerms,]))
freq <- data.frame(word=names(freq), freq=freq)
freq[order(-freq$freq), ][1:30, ]
freqTerms <- findFreqTerms(uniCorpus, lowfreq = 5)
freq <- rowSums(as.matrix(uniCorpus[freqTerms,]))
freq <- data.frame(word=names(freq), freq=freq)
freq[order(-freq$freq), ][1:30, ]
freqTerms <- findFreqTerms(uniCorpus, lowfreq = 5)
freqTerms
as.matrix(uniCorpus[freqTerms,])
freq <- rowSums(as.matrix(uniCorpus[freqTerms,]))
freq
freq <- data.frame(word=names(freq), freq=freq)
freq
freq[order(-freq$freq), ][1:30, ]
head(biCorpusM)
freqTerms <- findFreqTerms(x, lowfreq = 25)
freqTerms <- function(x) {
freqTerms <- findFreqTerms(x, lowfreq = 25)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable)
freqTable[order(-freqTable$freq), ][1:10, ]
}
freqTerms(uniCorpus)
freqTerms(biCorpus)
freqTerms(uniCorpus)
freqTerms(biCorpus)
freqTerms(triCorpus)
freqTerms <- function(x) {
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable)
freqTable[order(-freqTable$freq), ][1:10, ]
}
freqTerms(uniCorpus)
freqTerms(biCorpus)
freqTerms(triCorpus)
freqTerms <- function(x) {
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable)
kable(freqTable[order(-freqTable$freq), ][1:10, ], row.names=FALSE)
}
freqTerms(uniCorpus)
freqTerms(biCorpus)
freqTerms(triCorpus)
library("knitr")
freqTerms <- function(x) {
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable)
kable(freqTable[order(-freqTable$freq), ][1:10, ], row.names=FALSE)
}
freqTerms(uniCorpus)
freqTerms(biCorpus)
freqTerms(triCorpus)
freqTerms <- function(x) {
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable, rank=1:length(freqTable[,1]))
kable(freqTable[order(-freqTable$freq), ][1:10, ], row.names=FALSE)
}
freqTerms(uniCorpus)
freqTable
x <- uniCorpus
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable, rank=1:length(freqTable[,1]))
head(freqTable)
freqTable <- data.frame(word=names(freqTable), freq=freqTable, rank=1:length(freqTable[1]))
kable(freqTable[order(-freqTable$freq), ][1:10, ], row.names=FALSE)
freqTable <- data.frame(word=names(freqTable), freq=freqTable, rank=1:length(freqTable))
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable, rank=1:length(freqTable))
kable(freqTable[order(-freqTable$freq), ][1:10, ], row.names=FALSE)
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable)
freqTable <- freqTable[order(-freqTable$freq), ]
freqTable$rank <- 1:length(freqTable[,1])
kable(freqTable[1:10, ], row.names=FALSE)
freqTerms(uniCorpus)
freqTerms <- function(x) {
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable)
freqTable <- freqTable[order(-freqTable$freq), ]
freqTable$rank <- 1:length(freqTable[,1])
kable(freqTable[1:10, ], row.names=FALSE)
}
freqTerms(uniCorpus)
freqTerms(biCorpus)
freqTerms(triCorpus)
freqTerms <- function(x) {
freqTerms <- findFreqTerms(x, lowfreq = 5)
freqTable <- rowSums(as.matrix(x[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable)
freqTable <- freqTable[order(-freqTable$freq), ]
freqTable$rank <- 1:length(freqTable[,1])
kable(freqTable[1:10, c(3,1,2) ], row.names=FALSE)
}
freqTerms(uniCorpus)
freqTerms(biCorpus)
freqTerms(triCorpus)
print(corpus)
inspect(corpus)
row.sums(as.matrix(corpus))
rowSums(as.matrix(corpus))
rowSums(as.matrix(uniCorpus))
sum(rowSums(as.matrix(uniCorpus)))
library("knitr")
library("tm")
library("RWeka")
library("plyr")
library("ggplot2")
library("gridExtra")
library("SnowballC")
opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE, fig.height=5, fig.width=5)
news <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.news.sample.txt", stringsAsFactors=FALSE)
twitter <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.twitter.sample.txt", stringsAsFactors=FALSE)
blog <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.blog.sample.txt", stringsAsFactors=FALSE)
newsTT <- WordTokenizer(unlist(news))
twitterTT <- WordTokenizer(unlist(twitter))
blogTT <- WordTokenizer(unlist(blog))
wordTable <- data.frame(
Corpus=c("News 5% Sample", "Twitter 5% Sample", "Blog 5% Sample"),
Total.Tokens=c(length(newsTT), length(twitterTT), length(blogTT)),
Unique.Tokens=c(length(unique(newsTT)), length(unique(twitterTT)), length(unique(blogTT)))
)
kable(wordTable, row.names=FALSE)
newsFreq <- count(newsTT)
newsFreq <- newsFreq[order(newsFreq$freq, decreasing=TRUE), ]
newsFreq$Rank <- 1:length(newsFreq[,1])
twitterFreq <- count(twitterTT)
twitterFreq <- twitterFreq[order(twitterFreq$freq, decreasing=TRUE), ]
twitterFreq$Rank <- 1:length(twitterFreq[,1])
blogFreq <- count(blogTT)
blogFreq <- blogFreq[order(blogFreq$freq, decreasing=TRUE), ]
blogFreq$Rank <- 1:length(blogFreq[,1])
freqTable <- cbind(newsFreq[1:10, c(3,1,2)], twitterFreq[1:10, 1:2], blogFreq[1:10, 1:2])
colnames(freqTable) <- c("Rank", "News", "f", "Twitter", "f", "Blog", "f")
kable(freqTable, row.names=FALSE)
freqTerms(uniCorpus)
kable(freqTable[1:10, c(3,1,2) ], row.names=FALSE)
return(freqTable)
freqTerms <- findFreqTerms(uniCorpus, lowfreq = 5)
freqTable <- rowSums(as.matrix(uniCorpus[freqTerms,]))
freqTable <- data.frame(word=names(freqTable), freq=freqTable)
freqTable <- freqTable[order(-freqTable$freq), ]
freqTable$rank <- 1:length(freqTable[,1])
kable(freqTable[1:10, c(3,1,2) ], row.names=FALSE)
hist(log10(freqTable$freq))
ggplot(freqTable, aes(log10(freq), log10(Rank))) + geom_line(aes(color="Sample")) + labs(title="Zipf's Law") + theme(panel.background=element_blank())
ggplot(freqTable, aes(log10(freq), log10(rank))) + geom_line(aes(color="Sample")) + labs(title="Zipf's Law") + theme(panel.background=element_blank())
ggplot(freqTable, aes(log10(freq), log10(rank))) + geom_line(color="red") + labs(title="Zipf's Law") + theme(panel.background=element_blank())
freqTerms2 <- findFreqTerms(biCorpus, lowfreq = 5)
freqTable2 <- rowSums(as.matrix(biCorpus[freqTerms2,]))
freqTable2 <- data.frame(word=names(freqTable2), freq=freqTable2)
freqTable2 <- freqTable2[order(-freqTable2$freq), ]
freqTable2$rank <- 1:length(freqTable2[,1])
kable(freqTable2[1:10, c(3,1,2) ], row.names=FALSE)
freqTerms3 <- findFreqTerms(triCorpus, lowfreq = 5)
freqTable3 <- rowSums(as.matrix(triCorpus[freqTerms3,]))
freqTable3 <- data.frame(word=names(freqTable3), freq=freqTable3)
freqTable3 <- freqTable3[order(-freqTable3$freq), ]
freqTable3$rank <- 1:length(freqTable3[,1])
kable(freqTable3[1:10, c(3,1,2) ], row.names=FALSE)
hist(log10(freqTable2$freq))
hist(log10(freqTable3$freq))
allWordInstances <- sum(freqTerms$freq)
head(freqTerms)
allWordInstances <- sum(freqTable$freq)
halfWI <- allWordInstances*0.5
ninetyWI <- allWordInstances*0.9
halfWI <- allWordInstances*0.5
ninetyWI <- allWordInstances*0.9
freqTable$Sum <- cumsum(freqTable$freq)
fifty <- subset(freqTable, freqTable$Sum > halfWI)
fifty <- fifty[1,3]
ninety <- subset(freqTable, freqTable$Sum > ninetyWI)
ninety <- ninety[1,3]
