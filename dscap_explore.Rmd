Data Science Capstone NLP Exploratory Analysis
=============================
```{r setOpts, warning=FALSE, message=FALSE}
library("knitr")
library("tm")
library("RWeka")
opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE)
```

```{r readNews, eval=FALSE}
newsCon <- file("Desktop/data/en_US.news.txt", "r")
newsC <- readLines(newsCon)
close(newsCon)

newsLength <- length(newsC)
newsAvgChar <- round(sum(nchar(newsC))/newsLength,0)
newsSum <- summary(nchar(newsC))

news <- sample(newsC, length(newsC)*.05)
write.table(news, "en_US.news.sample.txt")
```

```{r readTwitter, eval=FALSE}
twitterCon <- file("Desktop/data/en_US.twitter.txt", "r")
twitterC <- readLines(twitterCon)
close(twitterCon)

twitterLength <- length(twitterC)
twitterAvgChar <- round(sum(nchar(twitterC))/twitterLength,0)
twitterSum <- summary(nchar(twitterC))

twitter <- sample(twitterC, length(twitterC)*.05)
write.table(twitter, "en_US.twitter.sample.txt")
```

```{r readBlog, eval=FALSE}
blogCon <- file("Desktop/data/en_US.blogs.txt", "r")
blogC <- readLines(blogCon)
close(blogCon)

blogLength <- length(blogC)
blogAvgChar <- round(sum(nchar(blogC))/blogLength,0)
blogSum <- summary(nchar(blogC))

blog <- sample(blogC, length(blogC)*.05)
write.table(blog, "en_US.blog.sample.txt")

```

```{r tables, eval=FALSE}
table <- data.frame(Type=c("News", "Twitter", "Blog"), Lines=c(newsLength, twitterLength, blogLength), Avg.Char.Per.Line=c(newsAvgChar, twitterAvgChar, blogAvgChar))

summary <- rbind(newsSum, twitterSum, blogSum)
row.names(summary) <- c("News", "Twitter", "Blog")

summary

hist(nchar(news))
hist(nchar(twitter))
hist(nchar(blog))
# total words in corpus (tokens)
# unique words in corpus (unique tokens)
# counts of 10 most frequent wors

```

```{r loadSamples}
news <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.news.sample.txt", stringsAsFactors=FALSE)
twitter <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.twitter.sample.txt", stringsAsFactors=FALSE)
blog <- read.table("/Users/kwalker/git_projects/DS_Capstone/data/en_US.blog.sample.txt", stringsAsFactors=FALSE)
```

```{r cleanCorpus}
# Remove unwanted characters (HTML tags, etc.)


# Word boundaires (white space, punctuation [consider Ph.D., isn't, e-mail])
test <- twitter[1:10,]
test <- paste(test, collapse=" ")
test <- strsplit(test, "\\?+ |\\!+ |\\.+ ")

# Stemming (optional, most common is Porter Stemmer)

# Stopword removal (the, a, of, for, in; SMART is a common stopword list) - is this helpful for this ???



```
